model {
    use_encoder = True
    use_global_encoder = False
    use_xyz = True
    canon_xyz = False
    # Positional encoding
    use_code = True
    code {
        num_freqs = 6
        freq_factor = 1.5
        include_input = True
    }

    # Apply positional encoding to viewdirs (only if use_code)
    use_code_viewdirs = True
    mlp_coarse {
        type = resnet
        n_blocks = 3
        d_hidden = 512
    }
    mlp_fine {
        type = resnet
        n_blocks = 3
        d_hidden = 512
    }
    encoder {
        backbone = resnet34
        pretrained = True
        num_layers = 4
    }
}
renderer {
    n_coarse = 32
    n_fine = 64
    sched = []
}
loss {
    rgb {
        use_l1 = False
    }
    rgb_fine {
        use_l1 = False
    }
    alpha {
        # lambda_alpha = 0.0001
        lambda_alpha = 0.0
        clamp_alpha = 100
        init_epoch = 5
    }
    lambda_coarse = 1.0  # loss = lambda_coarse * loss_coarse + loss_fine
    lambda_fine = 1.0  # loss = lambda_coarse * loss_coarse + loss_fine
}
train {
    print_interval = 2
    save_interval = 50
    vis_interval = 100
    eval_interval = 50

    # Accumulating gradients. Not really recommended.
    accu_grad = 1

    # Number of times to repeat dataset per 'epoch'
    # Useful if dataset is extremely small, like DTU
    num_epoch_repeats = 1
}
